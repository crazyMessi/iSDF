#!/usr/bin/env python3
"""
è¡¨é¢é‡‡æ ·æ•°æ®åŠ è½½å™¨æµ‹è¯•è„šæœ¬

ç”¨äºå¿«é€Ÿæµ‹è¯• SurfaceSamplingDataset çš„åŸºæœ¬åŠŸèƒ½
"""

import os
import numpy as np
import open3d as o3d
from surface_sampling_dataloader import SurfaceSamplingDataset, get_surface_sampling_dataloader


def create_test_mesh(save_path="test_data/"):
    """
    åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•ç½‘æ ¼ï¼ˆçƒä½“ï¼‰ç”¨äºæµ‹è¯•
    """
    if not os.path.exists(save_path):
        os.makedirs(save_path)
    
    # åˆ›å»ºçƒä½“ç½‘æ ¼
    mesh = o3d.geometry.TriangleMesh.create_sphere(radius=1.0, resolution=20)
    mesh.compute_vertex_normals()
    
    # ä¿å­˜ä¸º PLY æ–‡ä»¶
    mesh_file = os.path.join(save_path, "test_sphere.ply")
    o3d.io.write_triangle_mesh(mesh_file, mesh)
    
    # åˆ›å»ºç«‹æ–¹ä½“ç½‘æ ¼
    cube = o3d.geometry.TriangleMesh.create_box(width=1.0, height=1.0, depth=1.0)
    cube.compute_vertex_normals()
    cube_file = os.path.join(save_path, "test_cube.ply")
    o3d.io.write_triangle_mesh(cube_file, cube)
    
    print(f"æµ‹è¯•ç½‘æ ¼å·²åˆ›å»ºåœ¨: {save_path}")
    return save_path


def test_basic_dataset():
    """
    æµ‹è¯•åŸºæœ¬æ•°æ®é›†åŠŸèƒ½
    """
    print("=== æµ‹è¯•åŸºæœ¬æ•°æ®é›†åŠŸèƒ½ ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    data_path = create_test_mesh()
    
    try:
        # åˆ›å»ºæ•°æ®é›†
        dataset = SurfaceSamplingDataset(
            data_path=data_path,
            num_samples=512,
            normalize=True
        )
        
        print(f"âœ“ æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼ŒåŒ…å« {len(dataset)} ä¸ªç½‘æ ¼")
        
        if len(dataset) > 0:
            # æµ‹è¯•ç¬¬ä¸€ä¸ªæ ·æœ¬
            points, normals, vertices, faces = dataset[0]
            
            print(f"âœ“ æ•°æ®å½¢çŠ¶æ£€æŸ¥:")
            print(f"  - é‡‡æ ·ç‚¹: {points.shape}")
            print(f"  - æ³•å‘é‡: {normals.shape}")
            print(f"  - åŸå§‹é¡¶ç‚¹: {vertices.shape}")
            print(f"  - é¢ç‰‡: {faces.shape}")
            
            # éªŒè¯æ•°æ®ç±»å‹
            assert points.dtype == np.float32, f"é‡‡æ ·ç‚¹æ•°æ®ç±»å‹é”™è¯¯: {points.dtype}"
            assert normals.dtype == np.float32, f"æ³•å‘é‡æ•°æ®ç±»å‹é”™è¯¯: {normals.dtype}"
            assert faces.dtype == np.int32, f"é¢ç‰‡æ•°æ®ç±»å‹é”™è¯¯: {faces.dtype}"
            print("âœ“ æ•°æ®ç±»å‹æ£€æŸ¥é€šè¿‡")
            
            # éªŒè¯å½¢çŠ¶
            assert points.shape == (512, 3), f"é‡‡æ ·ç‚¹å½¢çŠ¶é”™è¯¯: {points.shape}"
            assert normals.shape == (512, 3), f"æ³•å‘é‡å½¢çŠ¶é”™è¯¯: {normals.shape}"
            assert vertices.shape[1] == 3, f"é¡¶ç‚¹å½¢çŠ¶é”™è¯¯: {vertices.shape}"
            assert faces.shape[1] == 3, f"é¢ç‰‡å½¢çŠ¶é”™è¯¯: {faces.shape}"
            print("âœ“ æ•°æ®å½¢çŠ¶æ£€æŸ¥é€šè¿‡")
            
            # éªŒè¯æ³•å‘é‡å½’ä¸€åŒ–
            normal_lengths = np.linalg.norm(normals, axis=1)
            assert np.allclose(normal_lengths, 1.0, atol=1e-5), "æ³•å‘é‡æœªæ­£ç¡®å½’ä¸€åŒ–"
            print("âœ“ æ³•å‘é‡å½’ä¸€åŒ–æ£€æŸ¥é€šè¿‡")
            
            # éªŒè¯æ•°æ®èŒƒå›´ï¼ˆæ ‡å‡†åŒ–ååº”è¯¥åœ¨ [-1, 1] èŒƒå›´å†…ï¼‰
            assert np.all(points >= -1.5) and np.all(points <= 1.5), "æ ‡å‡†åŒ–åçš„ç‚¹è¶…å‡ºåˆç†èŒƒå›´"
            print("âœ“ æ•°æ®èŒƒå›´æ£€æŸ¥é€šè¿‡")
            
        return True
        
    except Exception as e:
        print(f"âœ— åŸºæœ¬æ•°æ®é›†æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_dataloader():
    """
    æµ‹è¯•æ•°æ®åŠ è½½å™¨åŠŸèƒ½
    """
    print("\n=== æµ‹è¯•æ•°æ®åŠ è½½å™¨åŠŸèƒ½ ===")
    
    data_path = "test_data/"
    
    try:
        # æµ‹è¯• NumPy ç‰ˆæœ¬
        dataloader_np = get_surface_sampling_dataloader(
            data_path=data_path,
            num_samples=256,
            batch_size=2,
            shuffle=False,
            use_torch=False
        )
        
        print(f"âœ“ NumPy æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸï¼Œæ‰¹æ¬¡æ•°: {len(dataloader_np)}")
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        for batch_idx, (points, normals, vertices, faces) in enumerate(dataloader_np):
            print(f"âœ“ NumPy æ‰¹æ¬¡ {batch_idx} æ•°æ®å½¢çŠ¶:")
            print(f"  - é‡‡æ ·ç‚¹: {points.shape}")
            print(f"  - æ³•å‘é‡: {normals.shape}")
            assert len(points.shape) == 3, "æ‰¹æ¬¡æ•°æ®åº”è¯¥æ˜¯3ç»´"
            assert points.shape[1] == 256, f"é‡‡æ ·ç‚¹æ•°é”™è¯¯: {points.shape[1]}"
            break
        
        # æµ‹è¯• PyTorch ç‰ˆæœ¬
        try:
            import torch
            dataloader_torch = get_surface_sampling_dataloader(
                data_path=data_path,
                num_samples=256,
                batch_size=2,
                shuffle=False,
                use_torch=True,
                device='cpu'
            )
            
            print(f"âœ“ PyTorch æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
            
            # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
            for batch_idx, (points, normals, vertices, faces) in enumerate(dataloader_torch):
                print(f"âœ“ PyTorch æ‰¹æ¬¡ {batch_idx} æ•°æ®:")
                print(f"  - é‡‡æ ·ç‚¹: {points.shape}, ç±»å‹: {type(points)}")
                print(f"  - è®¾å¤‡: {points.device}")
                assert torch.is_tensor(points), "åº”è¯¥è¿”å› PyTorch å¼ é‡"
                break
                
        except ImportError:
            print("âš  PyTorch æœªå®‰è£…ï¼Œè·³è¿‡ PyTorch æµ‹è¯•")
        
        return True
        
    except Exception as e:
        print(f"âœ— æ•°æ®åŠ è½½å™¨æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_preprocessing_cache():
    """
    æµ‹è¯•é¢„å¤„ç†å’Œç¼“å­˜åŠŸèƒ½
    """
    print("\n=== æµ‹è¯•é¢„å¤„ç†å’Œç¼“å­˜åŠŸèƒ½ ===")
    
    data_path = "test_data/"
    save_path = "test_processed/"
    
    try:
        # ç¬¬ä¸€æ¬¡åˆ›å»ºï¼ˆä¼šè¿›è¡Œé¢„å¤„ç†ï¼‰
        print("ç¬¬ä¸€æ¬¡åˆ›å»ºæ•°æ®é›†ï¼ˆé¢„å¤„ç†ï¼‰...")
        dataset1 = SurfaceSamplingDataset(
            data_path=data_path,
            num_samples=128,
            save_path=save_path
        )
        
        # æ£€æŸ¥é¢„å¤„ç†æ–‡ä»¶æ˜¯å¦åˆ›å»º
        assert os.path.exists(save_path + "sampled_points.npy"), "é¢„å¤„ç†æ–‡ä»¶æœªåˆ›å»º"
        print("âœ“ é¢„å¤„ç†æ–‡ä»¶åˆ›å»ºæˆåŠŸ")
        
        # ç¬¬äºŒæ¬¡åˆ›å»ºï¼ˆåº”è¯¥åŠ è½½ç¼“å­˜ï¼‰
        print("ç¬¬äºŒæ¬¡åˆ›å»ºæ•°æ®é›†ï¼ˆåŠ è½½ç¼“å­˜ï¼‰...")
        dataset2 = SurfaceSamplingDataset(
            data_path=data_path,
            num_samples=128,
            save_path=save_path
        )
        
        # éªŒè¯ä¸¤æ¬¡åˆ›å»ºçš„ç»“æœä¸€è‡´
        if len(dataset1) > 0 and len(dataset2) > 0:
            points1, _, _, _ = dataset1[0]
            points2, _, _, _ = dataset2[0]
            assert np.allclose(points1, points2), "ç¼“å­˜åŠ è½½çš„æ•°æ®ä¸ä¸€è‡´"
            print("âœ“ ç¼“å­˜æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥é€šè¿‡")
        
        return True
        
    except Exception as e:
        print(f"âœ— é¢„å¤„ç†å’Œç¼“å­˜æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def test_mesh_normalization():
    """
    æµ‹è¯•ç½‘æ ¼æ ‡å‡†åŒ–åŠŸèƒ½
    """
    print("\n=== æµ‹è¯•ç½‘æ ¼æ ‡å‡†åŒ–åŠŸèƒ½ ===")
    
    data_path = "test_data/"
    
    try:
        # æµ‹è¯•æ ‡å‡†åŒ–ç‰ˆæœ¬
        dataset_norm = SurfaceSamplingDataset(
            data_path=data_path,
            num_samples=256,
            normalize=True
        )
        
        # æµ‹è¯•éæ ‡å‡†åŒ–ç‰ˆæœ¬
        dataset_no_norm = SurfaceSamplingDataset(
            data_path=data_path,
            num_samples=256,
            normalize=False
        )
        
        if len(dataset_norm) > 0:
            points_norm, _, vertices_norm, _ = dataset_norm[0]
            points_no_norm, _, vertices_no_norm, _ = dataset_no_norm[0]
            
            # æ ‡å‡†åŒ–ç‰ˆæœ¬çš„æ•°æ®åº”è¯¥åœ¨æ›´å°çš„èŒƒå›´å†…
            norm_range = np.ptp(points_norm)  # æå·®
            no_norm_range = np.ptp(points_no_norm)
            
            print(f"æ ‡å‡†åŒ–ç‰ˆæœ¬æ•°æ®èŒƒå›´: {norm_range:.3f}")
            print(f"éæ ‡å‡†åŒ–ç‰ˆæœ¬æ•°æ®èŒƒå›´: {no_norm_range:.3f}")
            
            # æ ‡å‡†åŒ–ç‰ˆæœ¬åº”è¯¥æ¥è¿‘ [-1, 1] çš„èŒƒå›´
            assert norm_range < 3.0, "æ ‡å‡†åŒ–åçš„æ•°æ®èŒƒå›´è¿‡å¤§"
            print("âœ“ ç½‘æ ¼æ ‡å‡†åŒ–åŠŸèƒ½æ­£å¸¸")
        
        return True
        
    except Exception as e:
        print(f"âœ— ç½‘æ ¼æ ‡å‡†åŒ–æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


def cleanup_test_files():
    """
    æ¸…ç†æµ‹è¯•æ–‡ä»¶
    """
    import shutil
    
    test_dirs = ["test_data/", "test_processed/"]
    for dir_path in test_dirs:
        if os.path.exists(dir_path):
            shutil.rmtree(dir_path)
    
    test_files = ["sampled_surface_001.ply"]
    for file_path in test_files:
        if os.path.exists(file_path):
            os.remove(file_path)
    
    print("âœ“ æµ‹è¯•æ–‡ä»¶æ¸…ç†å®Œæˆ")


def main():
    """
    è¿è¡Œæ‰€æœ‰æµ‹è¯•
    """
    print("å¼€å§‹è¿è¡Œè¡¨é¢é‡‡æ ·æ•°æ®åŠ è½½å™¨æµ‹è¯•")
    print("=" * 50)
    
    test_results = []
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    test_results.append(("åŸºæœ¬æ•°æ®é›†åŠŸèƒ½", test_basic_dataset()))
    test_results.append(("æ•°æ®åŠ è½½å™¨åŠŸèƒ½", test_dataloader()))
    test_results.append(("é¢„å¤„ç†å’Œç¼“å­˜", test_preprocessing_cache()))
    test_results.append(("ç½‘æ ¼æ ‡å‡†åŒ–", test_mesh_normalization()))
    
    # è¾“å‡ºæµ‹è¯•ç»“æœ
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœæ±‡æ€»:")
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"  {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    # æ¸…ç†æµ‹è¯•æ–‡ä»¶
    cleanup_test_files()
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®åŠ è½½å™¨å·¥ä½œæ­£å¸¸ã€‚")
        return True
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 